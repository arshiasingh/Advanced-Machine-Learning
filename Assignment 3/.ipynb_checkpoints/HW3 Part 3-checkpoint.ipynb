{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun April 5th\n",
    "\n",
    "@author: Joshuah Touyz\n",
    "@class: Anly-601\n",
    "@title: HW3 Part 3\n",
    "@lecture: L11 - Intro to deep learning\n",
    "\"\"\"\n",
    "# ---- Programming backprop from scratch -----\n",
    "##########################\n",
    "#   Importing libraries  #\n",
    "##########################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as py\n",
    "import time\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#   Generate some training    #\n",
    "#      data from a GMM        #\n",
    "###############################\n",
    "def gen_gmm_data(n = 999, plot=False):\n",
    "    # Fixing seed for repeatability\n",
    "    np.random.seed(123)\n",
    "    \n",
    "    # Parameters of a normal distribuion\n",
    "    mean_1 = [0, 2] ; mean_2 = [2, -2] ; mean_3 = [-2, -2]\n",
    "    mean = [mean_1, mean_2, mean_3] ; cov = [[1, 0], [0, 1]]  \n",
    "    \n",
    "    # Setting up the class probabilities\n",
    "    n_samples = n\n",
    "    pr_class_1 = pr_class_2 = pr_class_3 = 1/3.0\n",
    "    n_class = (n_samples * np.array([pr_class_1,pr_class_2, pr_class_3])).astype(int)\n",
    "  \n",
    "    # Generate sample data\n",
    "    for i in range(3):\n",
    "        x1,x2 = np.random.multivariate_normal(mean[i], cov, n_class[i]).T\n",
    "        if (i==0):\n",
    "            xs = np.array([x1,x2])\n",
    "            cl = np.array([n_class[i]*[i]])\n",
    "        else: \n",
    "            xs_new = np.array([x1,x2])\n",
    "            cl_new = np.array([n_class[i]*[i]])\n",
    "            xs = np.concatenate((xs, xs_new), axis = 1)\n",
    "            cl = np.concatenate((cl, cl_new), axis = 1)\n",
    "    \n",
    "    # Plot?\n",
    "    if plot:\n",
    "        py.scatter(xs[:1,:],xs[1:,:], c = cl)\n",
    "\n",
    "    # One hot encoding classes\n",
    "    y = pd.Series(cl[0].tolist())\n",
    "    y = pd.get_dummies(y).as_matrix() \n",
    "\n",
    "    # Normalizing data (prevents overflow errors)     \n",
    "    mu = xs.mean(axis = 1)\n",
    "    std = xs.std(axis = 1)\n",
    "    xs = (xs.T - mu) / std\n",
    "    \n",
    "    return xs, y, cl\n",
    "             \n",
    "xs,y,cl = gen_gmm_data(plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuahtouyz/Desktop/projects/project_1/p1_venv/lib/python3.7/site-packages/ipykernel_launcher.py:53: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "#%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#    Hidden Units     #\n",
    "#######################\n",
    "ReLU = np.vectorize(lambda z: np.fmax(0,z))\n",
    "sigmoid = lambda z: 1 / (1 + np.exp(-z))\n",
    "softmax = lambda z: np.exp(z)/(np.sum(np.exp(z),axis=1))[:,np.newaxis]\n",
    "\n",
    "# %%%%%%%%%%%%%%%%%%%%%\n",
    "#  Utility Functions  #\n",
    "# #####################\n",
    "def predict(Y_hat):\n",
    "    return np.argmax(Y_hat, axis=1)\n",
    "\n",
    "\n",
    "def error_rate(Y_hat, cl):\n",
    "    prediction = predict(Y_hat)\n",
    "    return np.mean(prediction != cl)\n",
    "\n",
    "\n",
    "def cost(Y_hat, Y):\n",
    "    tot = Y * np.log(Y_hat)\n",
    "    return -tot.sum()\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#   1- Hidden Layer ReLU Network   #\n",
    "####################################\n",
    "def forward(X,parameters, drop_out = 1):\n",
    "    # Unpacking parameters    \n",
    "    W,b1,V,b2 = parameters\n",
    "    \n",
    "    # Forward pass\n",
    "    a1 = X.dot(W) + b1\n",
    "    H = ReLU(a1) * drop_out\n",
    "    # H = sigmoid(a1) * drop_out\n",
    "    a2 = H.dot(V) + b2\n",
    "    Y_hat = softmax(a2)\n",
    "    return H,Y_hat\n",
    "\n",
    "#%%%%%%%%%%%%%%%\n",
    "#   Gradient   #\n",
    "################\n",
    "\n",
    "def grad(X,H,Y,Y_hat,parameters):  \n",
    "    # Unpacking parameters    \n",
    "    W,b1,V,b2 = parameters\n",
    "    # Gradients - ReLU\n",
    "    dV = H.T.dot(Y_hat - Y)\n",
    "    db2 = (Y_hat - Y).sum(axis=0)\n",
    "    dW = X.T.dot(((Y_hat - Y).dot(V.T) * (H > 0))) \n",
    "    db1 = ((Y_hat - Y).dot(V.T) * (H > 0)).sum(axis=0)\n",
    "    \n",
    "    # Gradients - sigmoid\n",
    "    # dW = X.T.dot((Y_hat-Y).dot(V) * (H * (1 - H)))\n",
    "    # db1 = (Y_hat-Y).dot(V) * (H * (1 - H)).sum(axis=0)\n",
    "    \n",
    "    \n",
    "    #return {'dV':dV,'db2':db2,'dW':dW,'db1':db1}\n",
    "    return dW,db1,dV,db2\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#   Parameter Update: Momentum + Regularization   #\n",
    "###################################################\n",
    "def parameter_update(parameters,  grads, \n",
    "                     momentum_params = [0,0,0,0], \n",
    "                     lr = 1, reg = 0, alpha = 0):\n",
    "    # Unpacking parameters            \n",
    "    W,b1,V,b2 = parameters\n",
    "    dW,db1,dV,db2 = grads\n",
    "    vW,vb1,vV,vb2 = momentum_params\n",
    "    \n",
    "    # Momentum update\n",
    "    vW  = alpha * vW -  lr * (dW + reg*W)\n",
    "    vb1 = alpha * vb1 - lr * (db1 + reg*b1)\n",
    "    vV  = alpha * vV -  lr * (dV + reg*V)\n",
    "    vb2 = alpha * vb2 - lr * (db2 + reg*b2)\n",
    "    momentum_params = [vW,vb1,vV,vb2] \n",
    "    \n",
    "    # Parameter updates\n",
    "    W  = W  + vW\n",
    "    b1 = b1 + vb1\n",
    "    V  = V  + vV\n",
    "    b2 = b2 + vb2\n",
    "    parameters =[W,b1,V,b2]\n",
    "\n",
    "             \n",
    "    return parameters, momentum_params\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#  Generate data for network    #\n",
    "#################################\n",
    "X, Y, cl = gen_gmm_data()\n",
    "\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#      Building the model     #\n",
    "###############################\n",
    "def run_model(X, Y, cl,\n",
    "              nodes_in_hidden_layer = 3,\n",
    "              num_dim = 2,     # <- number of dimensions here it is 2: x1,x2\n",
    "              num_classes = 3, # <- number of classes in the problem\n",
    "              iterations = 1000,\n",
    "              regularization_include = False,\n",
    "              momentum_include = False,\n",
    "              drop_out_include = False):    \n",
    "\n",
    "    \n",
    "    ###################################\n",
    "    #   Initial values for network    #\n",
    "    ###################################\n",
    "    # Intialize weights\n",
    "    np.random.seed(123)\n",
    "    W = np.random.randn(num_dim * nodes_in_hidden_layer).reshape(num_dim,nodes_in_hidden_layer)\n",
    "    b1 = 0\n",
    "    V = np.random.randn(num_classes * nodes_in_hidden_layer).reshape(nodes_in_hidden_layer,num_classes)\n",
    "    b2 = 0\n",
    "    parameters = [W,b1,V,b2]\n",
    "    \n",
    "    \n",
    "    # Hyperparameters \n",
    "    lr = 0.0001 # learning rate\n",
    "    reg = 0.01 * regularization_include\n",
    "    \n",
    "    # Momentum parameters\n",
    "    alpha = 0.9 * momentum_include\n",
    "    vV = 0\n",
    "    vb2 = 0\n",
    "    vW = 0\n",
    "    vb1 = 0\n",
    "    momentum_params = [vW,vb1,vV,vb2]    \n",
    "    \n",
    "    # Place holder for losses\n",
    "    losses = []\n",
    "    errors = []    \n",
    "   \n",
    "    ###################\n",
    "    #   Run the model #\n",
    "    ###################\n",
    "    for i in range(0,iterations):\n",
    "        # -- Drop Out Mask --\n",
    "        # When !=1 then ddrop rate is 12.5%  (~0.5/4 = 12.5%)\n",
    "        # Short cut to include drop_out \n",
    "        drop_out =  (1 - drop_out_include) + drop_out_include * np.round(1-np.random.rand(nodes_in_hidden_layer)/4) \n",
    "        \n",
    "        # -- Forward propoagation --\n",
    "        H,Y_hat = forward(X,parameters,drop_out)\n",
    "        \n",
    "        # -- Backward propagation --\n",
    "        # Gradient calculation\n",
    "        grads_in = grad(X,H,Y,Y_hat,parameters)\n",
    "        # Parameter update\n",
    "        new_params, new_mom_param = parameter_update(parameters, grads_in, \n",
    "                             momentum_params, alpha = alpha, \n",
    "                             lr = lr, reg = reg)\n",
    "        \n",
    "        # -- Updating values --\n",
    "        H,Y_hat = forward(X,new_params, drop_out)\n",
    "        parameters = new_params\n",
    "        momentum_params = new_mom_param\n",
    "        # Prediction and Error rate            \n",
    "        errs_i = error_rate(Y_hat, cl) ; errors.append(errs_i)\n",
    "        loss_i = cost(Y_hat, Y); losses.append(loss_i)\n",
    "        if ((i % 25) == 0):    \n",
    "            print(\n",
    "            '''\n",
    "            ---- Iteration {i} ----\n",
    "            Error rate : {er}\n",
    "            Loss: {loss}\n",
    "            '''.format(i= i, er = errs_i, loss = loss_i))\n",
    "    return {\"errors\":errs_i, \"loss_i\":loss_i, \"parameters\":parameters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            ---- Iteration 0 ----\n",
      "            Error rate : 0.34234234234234234\n",
      "            Loss: 613.5034085448333\n",
      "            \n",
      "\n",
      "            ---- Iteration 25 ----\n",
      "            Error rate : 0.04504504504504504\n",
      "            Loss: 230.39605917572294\n",
      "            \n",
      "\n",
      "            ---- Iteration 50 ----\n",
      "            Error rate : 0.03303303303303303\n",
      "            Loss: 150.17197232981292\n",
      "            \n",
      "\n",
      "            ---- Iteration 75 ----\n",
      "            Error rate : 0.03003003003003003\n",
      "            Loss: 120.61145170075918\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#   Running Different Models  #\n",
    "###############################\n",
    "vanilla_sgd = run_model(X,Y,cl, iterations = 100,\n",
    "              regularization_include = False,\n",
    "              momentum_include = False,\n",
    "              drop_out_include = False)\n",
    "              \n",
    "sgd_w_reg = run_model(X,Y,cl, 100,\n",
    "              regularization_include = True,\n",
    "              momentum_include = False,\n",
    "              drop_out_include = False)\n",
    " \n",
    "sgd_w_reg_momentum = run_model(X,Y,cl, 100,\n",
    "                              regularization_include = True,\n",
    "                              momentum_include = True,\n",
    "                              drop_out_include = False)\n",
    "\n",
    "sgd_w_reg_momentum_drop_out = run_model(X,Y,cl, 100,\n",
    "                                      regularization_include = True,\n",
    "                                      momentum_include = True,\n",
    "                                      drop_out_include = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuahtouyz/Desktop/projects/project_1/p1_venv/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            ---- Iteration 0 ----\n",
      "            Error rate : 0.34234234234234234\n",
      "            Loss: 613.5034085448333\n",
      "            \n",
      "\n",
      "            ---- Iteration 25 ----\n",
      "            Error rate : 0.04504504504504504\n",
      "            Loss: 230.39605917572294\n",
      "            \n",
      "\n",
      "            ---- Iteration 50 ----\n",
      "            Error rate : 0.03303303303303303\n",
      "            Loss: 150.17197232981292\n",
      "            \n",
      "\n",
      "            ---- Iteration 75 ----\n",
      "            Error rate : 0.03003003003003003\n",
      "            Loss: 120.61145170075918\n",
      "            \n",
      "0.7856990000000081 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuahtouyz/Desktop/projects/project_1/p1_venv/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#       Execution time.      #\n",
    "###############################\n",
    "start_time = time.clock()\n",
    "run_model(X,Y,cl, iterations = 100,\n",
    "              regularization_include = False,\n",
    "              momentum_include = False,\n",
    "              drop_out_include = False)\n",
    "print(time.clock() - start_time, \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
